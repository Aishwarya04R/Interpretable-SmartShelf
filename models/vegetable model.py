# -*- coding: utf-8 -*-
"""Vegetable.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xcaF-Tf7SzkUlP0ox4lju8tIEP9N_85W
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import re
import cv2
import torch
import timm
import pandas as pd
import numpy as np
import torch.nn as nn
from pathlib import Path
from torch.utils.data import Dataset, DataLoader, Subset
import albumentations as A
from albumentations.pytorch import ToTensorV2

import os

print(os.path.exists("/content/drive/MyDrive"))
print(os.listdir("/content/drive/MyDrive")[:10])

import albumentations as A
from albumentations.pytorch import ToTensorV2

test_transform = A.Compose([
    A.Resize(224, 224),
    A.Normalize(
        mean=(0.485, 0.456, 0.406),
        std=(0.229, 0.224, 0.225)
    ),
    ToTensorV2()
])

from pathlib import Path

# set your dataset root folder
DATASET_DIR = Path("/content/drive/MyDrive/vegetable dataset")  # change this

# valid image extensions
IMG_EXT = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}

veg_counts = {}      # total images per vegetable
day_counts = {}      # images per day folder
total_images = 0

for veg_folder in DATASET_DIR.iterdir():
    if veg_folder.is_dir():
        veg_name = veg_folder.name
        veg_total = 0

        for day_folder in veg_folder.iterdir():
            if day_folder.is_dir():
                day_name = f"{veg_name}/{day_folder.name}"
                count = sum(1 for f in day_folder.rglob("*") if f.suffix.lower() in IMG_EXT)
                day_counts[day_name] = count
                veg_total += count
                total_images += count

        veg_counts[veg_name] = veg_total

print("üìå Images in each vegetable folder:")
for veg, count in veg_counts.items():
    print(f"{veg}: {count}")

print("\nüìå Images in each day subfolder:")
for day_folder, count in day_counts.items():
    print(f"{day_folder}: {count}")

print("\nüî• TOTAL IMAGES IN DATASET:", total_images)

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/vegetable dataset/metadata.csv")
print(df.head())
print(df.info())

DATASET_DIR = Path("/content/drive/MyDrive/vegetable dataset")
CSV_PATH = "/content/drive/MyDrive/vegetable dataset/metadata3.csv"
BEST_MODEL_PATH = "/content/drive/MyDrive/vegetable dataset/best_multitask_model3.pth"
device = "cpu"

rows = []
max_days = {}

for veg in DATASET_DIR.iterdir():
    if veg.is_dir():
        days = []
        for d in veg.iterdir():
            if d.is_dir():
                m = re.search(r"(?:day|d)_?0*([0-9]+)", d.name.lower())
                if m:
                    days.append(int(m.group(1)))
        max_days[veg.name] = max(days) if days else 0

def freshness_from_day(day):
    if day <= 2:
        return "fresh"
    elif day <= 3:
        return "mid"
    else:
        return "spoiled"

for veg in DATASET_DIR.iterdir():
    if veg.is_dir():
        for d in veg.iterdir():
            if d.is_dir():
                m = re.search(r"(?:day|d)_?0*([0-9]+)", d.name.lower())
                day = int(m.group(1)) if m else 0

                for img in d.rglob("*"):
                    if img.suffix.lower() in [".jpg",".jpeg",".png"]:
                        rows.append({
                            "filename": img.relative_to(DATASET_DIR).as_posix(),
                            "vegetable_label": veg.name,
                            "freshness_label": freshness_from_day(day),
                            "remaining_days": max(0, max_days[veg.name] - day)
                        })

df = pd.DataFrame(rows)
df.to_csv(CSV_PATH, index=False)
print("‚úÖ CSV GENERATED:", CSV_PATH)
print(df.head())

train_transform = A.Compose([
    A.Resize(96,96),
    A.RandomBrightnessContrast(0.1,0.1,p=0.5),
    A.HorizontalFlip(p=0.5),
    A.Normalize(mean=(0.485,0.456,0.406),
                std=(0.229,0.224,0.225)),
    ToTensorV2()
])

test_transform = A.Compose([
    A.Resize(96,96),
    A.Normalize(mean=(0.485,0.456,0.406),
                std=(0.229,0.224,0.225)),
    ToTensorV2()
])

class VegMultiTaskDataset(Dataset):
    def __init__(self, csv_path, root_dir, transform=None, veg_map=None):
        self.df = pd.read_csv(csv_path)
        self.root = root_dir
        self.transform = transform

        self.veg_map = veg_map
        self.fresh_map = {"fresh":0,"mid":1,"spoiled":2}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
      idx = int(idx)   # üî• VERY IMPORTANT FIX

      row = self.df.iloc[idx]
      img_path = f"{self.root}/{row['filename']}"

      img = cv2.imread(img_path)
      if img is None:
          raise ValueError(f"Failed to load image: {img_path}")

      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

      if self.transform:
          img = self.transform(image=img)["image"]

      veg = self.veg_map[row["vegetable_label"]]
      fresh = self.fresh_map[row["freshness_label"]]
      remaining = torch.tensor(row["remaining_days"], dtype=torch.float32)

      return img, veg, fresh, remaining

df = pd.read_csv(CSV_PATH)
shared_veg_map = {v:i for i,v in enumerate(sorted(df["vegetable_label"].unique()))}

train_dataset = VegMultiTaskDataset(CSV_PATH, DATASET_DIR, train_transform, shared_veg_map)
test_dataset  = VegMultiTaskDataset(CSV_PATH, DATASET_DIR, test_transform, shared_veg_map)

indices = torch.randperm(len(train_dataset))
split = int(0.8 * len(indices))
train_idx, test_idx = indices[:split], indices[split:]

train_ds = Subset(train_dataset, train_idx)
test_ds = Subset(test_dataset, test_idx)

train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=1)
test_loader  = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=1)

class MultiHeadEfficientNet(nn.Module):
    def __init__(self, num_veg_classes):
        super().__init__()
        self.backbone = timm.create_model("efficientnet_b0", pretrained=True, num_classes=0)
        feat = self.backbone.num_features
        self.drop = nn.Dropout(0.4)
        self.veg_head = nn.Linear(feat, num_veg_classes)
        self.fresh_head = nn.Linear(feat, 3)
        self.reg_head = nn.Linear(feat, 1)

    def forward(self, x):
        f = self.drop(self.backbone(x))
        return self.veg_head(f), self.fresh_head(f), self.reg_head(f).squeeze(1)

veg_loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)
fresh_loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)
reg_loss_fn = nn.L1Loss()

def test(model, loader, device):
    model.eval()
    correct_veg = 0
    correct_fresh = 0
    total = 0
    mae = 0.0

    with torch.no_grad():
        for imgs, veg, fresh, days in loader:
            imgs = imgs.to(device)
            veg = veg.to(device)
            fresh = fresh.to(device)
            days = days.to(device)

            veg_out, fresh_out, reg_out = model(imgs)

            correct_veg += (veg_out.argmax(1) == veg).sum().item()
            correct_fresh += (fresh_out.argmax(1) == fresh).sum().item()
            mae += torch.abs(reg_out - days).sum().item()
            total += veg.size(0)

    return correct_veg / total, correct_fresh / total, mae / total

model = MultiHeadEfficientNet(len(shared_veg_map)).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

EPOCHS = 25
MAX_BATCHES_PER_EPOCH = 30
best_mae = float("inf")

for epoch in range(EPOCHS):
    model.train()
    run_loss = 0

    for i,(x,v,f,d) in enumerate(train_loader):
        if i >= MAX_BATCHES_PER_EPOCH:
            break

        x,v,f,d = x.to(device),v.to(device),f.to(device),d.to(device)

        vo,fo,ro = model(x)

        loss = (
            3*veg_loss_fn(vo,v) +
            3*fresh_loss_fn(fo,f) +
            0.5*reg_loss_fn(ro,d)
        )

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        run_loss += loss.item()

    veg_acc, fresh_acc, mae = test(model, test_loader, device)

    print(
        f"Epoch {epoch+1}/{EPOCHS} | "
        f"Loss={run_loss:.3f} | "
        f"VegAcc={veg_acc*100:.2f}% | "
        f"FreshAcc={fresh_acc*100:.2f}% | "
        f"MAE={mae:.2f}"
    )

    if mae < best_mae:
        best_mae = mae
        torch.save({
            "model": model.state_dict(),
            "veg_map": shared_veg_map,
            "mae": best_mae
        }, BEST_MODEL_PATH)
        print("üíæ Best model saved")

import os

print(os.path.exists(BEST_MODEL_PATH))
print(BEST_MODEL_PATH)

checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)

model = MultiHeadEfficientNet(num_veg_classes=len(checkpoint["veg_map"])).to(device)
model.load_state_dict(checkpoint["model"])
model.eval()

veg_map = checkpoint["veg_map"]
inv_veg_map = {v:k for k,v in veg_map.items()}

veg_acc, fresh_acc, mae = test(model, test_loader, device)

print(f"‚úÖ Final Test Results")
print(f"Vegetable Accuracy : {veg_acc*100:.2f}%")
print(f"Freshness Accuracy : {fresh_acc*100:.2f}%")
print(f"MAE (days)         : {mae:.2f}")

import cv2

def predict_image(image_path):
    img = cv2.imread(image_path)

    if img is None:
        raise FileNotFoundError(f"Image not found: {image_path}")

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = test_transform(image=img)["image"].unsqueeze(0).to(device)

    with torch.no_grad():
        veg_out, fresh_out, reg_out = model(img)

    veg_pred = inv_veg_map[veg_out.argmax(1).item()]
    fresh_pred = ["fresh","mid","spoiled"][fresh_out.argmax(1).item()]
    days_pred = max(0.0, reg_out.item())   # üî• clamp here

    print("üîç Prediction Result")
    print("Vegetable        :", veg_pred)
    print("Freshness        :", fresh_pred)
    print("Remaining Days   :", round(days_pred, 2))

import torch
import cv2
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2

BEST_MODEL_PATH = "/content/drive/MyDrive/vegetable dataset/best_multitask_model3.pth"
device = "cpu"

import os
print(os.path.exists(BEST_MODEL_PATH))

class MultiHeadEfficientNet(nn.Module):
    def __init__(self, num_veg_classes):
        super().__init__()
        self.backbone = timm.create_model("efficientnet_b0", pretrained=False, num_classes=0)
        feat = self.backbone.num_features
        self.drop = nn.Dropout(0.4)
        self.veg_head = nn.Linear(feat, num_veg_classes)
        self.fresh_head = nn.Linear(feat, 3)
        self.reg_head = nn.Linear(feat, 1)

    def forward(self, x):
        f = self.drop(self.backbone(x))
        return self.veg_head(f), self.fresh_head(f), self.reg_head(f).squeeze(1)

checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)

model = MultiHeadEfficientNet(num_veg_classes=len(checkpoint["veg_map"])).to(device)
model.load_state_dict(checkpoint["model"])
model.eval()

veg_map = checkpoint["veg_map"]
inv_veg_map = {v:k for k,v in veg_map.items()}

print("Model loaded successfully")
print("Vegetable classes:", inv_veg_map)

import glob

paths = glob.glob("/content/drive/MyDrive/vegetable dataset/potato/Day05/*.png")
predict_image(paths[0])

import torch
import pandas as pd
import cv2
from torch.utils.data import DataLoader, random_split

import albumentations as A
from albumentations.pytorch import ToTensorV2

test_transform = A.Compose([
    A.Resize(224,224),
    A.Normalize(
        mean=(0.485,0.456,0.406),
        std=(0.229,0.224,0.225)
    ),
    ToTensorV2()
])

class VegMultiTaskDataset(torch.utils.data.Dataset):
    def __init__(self, csv_path, root_dir, transform=None):
        self.df = pd.read_csv(csv_path)
        self.root = root_dir
        self.transform = transform
        self.veg_map = {v:i for i,v in enumerate(self.df["vegetable_label"].unique())}
        self.fresh_map = {"fresh":0,"mid":1,"spoiled":2}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        idx = int(idx)
        row = self.df.iloc[idx]
        img = cv2.imread(f"{self.root}/{row['filename']}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        if self.transform:
            img = self.transform(image=img)["image"]
        return (
            img,
            self.veg_map[row["vegetable_label"]],
            self.fresh_map[row["freshness_label"]],
            torch.tensor(row["remaining_days"], dtype=torch.float32)
        )

CSV_PATH = "/content/drive/MyDrive/vegetable dataset/metadata3.csv"
ROOT_DIR = "/content/drive/MyDrive/vegetable dataset"

dataset = VegMultiTaskDataset(
    csv_path=CSV_PATH,
    root_dir=ROOT_DIR,
    transform=test_transform
)

train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
_, test_ds = random_split(dataset, [train_size, test_size])

test_loader = DataLoader(
    test_ds,
    batch_size=32,
    shuffle=False
)

model.eval()
with torch.no_grad():
    for x,v,_,_ in test_loader:
        x = x.to(device)
        v = v.to(device)
        break  # test one batch

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_true_veg = []
y_pred_veg = []

model.eval()
with torch.no_grad():
    for x, v, _, _ in test_loader:
        x = x.to(device)
        v = v.to(device)

        veg_out, _, _ = model(x)
        preds = veg_out.argmax(1)

        y_true_veg.extend(v.cpu().numpy())
        y_pred_veg.extend(preds.cpu().numpy())

cm_veg = confusion_matrix(y_true_veg, y_pred_veg)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm_veg,
    display_labels=[inv_veg_map[i] for i in range(len(inv_veg_map))]
)
disp.plot(cmap="Blues", xticks_rotation=45)
plt.title("Vegetable Classification Confusion Matrix")
plt.show()

y_true_fresh = []
y_pred_fresh = []

model.eval()
with torch.no_grad():
    for x, _, f, _ in test_loader:
        x = x.to(device)
        f = f.to(device)

        _, fresh_out, _ = model(x)
        preds = fresh_out.argmax(1)

        y_true_fresh.extend(f.cpu().numpy())
        y_pred_fresh.extend(preds.cpu().numpy())

cm_fresh = confusion_matrix(y_true_fresh, y_pred_fresh)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm_fresh,
    display_labels=["fresh", "mid", "spoiled"]
)
disp.plot(cmap="Oranges")
plt.title("Freshness Classification Confusion Matrix")
plt.show()

import seaborn as sns

plt.figure(figsize=(6,5))
sns.heatmap(
    cm_veg,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=[inv_veg_map[i] for i in range(len(inv_veg_map))],
    yticklabels=[inv_veg_map[i] for i in range(len(inv_veg_map))]
)
plt.title("Vegetable Confusion Matrix (Heatmap)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

plt.figure(figsize=(5,4))
sns.heatmap(
    cm_fresh,
    annot=True,
    fmt="d",
    cmap="Oranges",
    xticklabels=["fresh","mid","spoiled"],
    yticklabels=["fresh","mid","spoiled"]
)
plt.title("Freshness Confusion Matrix (Heatmap)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()



"""**LOADING THE MODEL**

"""

import os
import torch
import torch.nn as nn
import cv2
import pandas as pd
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2

device = "cpu"   # you are using CPU

BEST_MODEL_PATH = "/content/drive/MyDrive/vegetable dataset/best_multitask_model3.pth"

class MultiHeadEfficientNet(nn.Module):
    def __init__(self, num_veg_classes):
        super().__init__()

        self.backbone = timm.create_model(
            "efficientnet_b0",
            pretrained=False,   # IMPORTANT: weights come from checkpoint
            num_classes=0
        )

        feat_dim = self.backbone.num_features
        self.dropout = nn.Dropout(0.4)

        self.veg_head = nn.Linear(feat_dim, num_veg_classes)
        self.fresh_head = nn.Linear(feat_dim, 3)
        self.reg_head = nn.Linear(feat_dim, 1)

    def forward(self, x):
        features = self.dropout(self.backbone(x))
        veg_out = self.veg_head(features)
        fresh_out = self.fresh_head(features)
        reg_out = self.reg_head(features).squeeze(1)
        return veg_out, fresh_out, reg_out

checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)

model = MultiHeadEfficientNet(
    num_veg_classes=len(checkpoint["veg_map"])
).to(device)

model.load_state_dict(checkpoint["model"])
model.eval()

veg_map = checkpoint["veg_map"]
inv_veg_map = {v: k for k, v in veg_map.items()}

print("‚úÖ Model loaded successfully")
print("Vegetable classes:", inv_veg_map)

test_transform = A.Compose([
    A.Resize(224, 224),
    A.Normalize(
        mean=(0.485, 0.456, 0.406),
        std=(0.229, 0.224, 0.225)
    ),
    ToTensorV2()
])



def predict_image(image_path):
    img = cv2.imread(image_path)

    if img is None:
        raise FileNotFoundError(f"Image not found: {image_path}")

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = test_transform(image=img)["image"].unsqueeze(0).to(device)

    with torch.no_grad():
        veg_out, fresh_out, reg_out = model(img)

    veg_pred = inv_veg_map[veg_out.argmax(1).item()]
    fresh_pred = ["fresh", "mid", "spoiled"][fresh_out.argmax(1).item()]
    days_pred = max(0.0, reg_out.item())   # clamp negative values

    print("üîç Prediction Result")
    print("Vegetable        :", veg_pred)
    print("Freshness        :", fresh_pred)
    print("Remaining Days   :", round(days_pred, 2))

print(os.path.exists(BEST_MODEL_PATH))

from PIL import Image
import matplotlib.pyplot as plt

def show_image(image_path, title="Input Image"):
    img = Image.open(image_path)
    plt.figure(figsize=(4,4))
    plt.imshow(img)
    plt.axis("off")
    plt.title(title)
    plt.show()

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename="camera.jpg", width=320):
    js = Javascript(f"""
    async function takePhoto() {{
        const video = document.createElement('video');
        const stream = await navigator.mediaDevices.getUserMedia({{video:true}});
        document.body.appendChild(video);

        video.style.width = "{width}px";
        video.style.border = "2px solid #444";
        video.style.borderRadius = "8px";

        video.srcObject = stream;
        await video.play();

        await new Promise(r => setTimeout(r,2000));

        const canvas = document.createElement('canvas');
        const ratio = video.videoHeight / video.videoWidth;
        canvas.width = {width};
        canvas.height = {width} * ratio;

        canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);

        stream.getTracks().forEach(t => t.stop());
        video.remove();

        return canvas.toDataURL('image/jpeg');
    }}
    takePhoto();
    """)
    display(js)

    data = eval_js("takePhoto()")
    with open(filename, "wb") as f:
        f.write(b64decode(data.split(",")[1]))

    return filename

from google.colab import files
from PIL import Image

def run_demo():
    print("="*32)
    print(" Vegetable Shelf Life Predictor ")
    print("="*32)
    print("1Ô∏è‚É£  Camera Capture")
    print("2Ô∏è‚É£  Upload Image")

    choice = input("Enter 1 or 2: ").strip()

    if choice == "1":
        print("\nüì∏ Opening camera...")
        img_path = take_photo()
    elif choice == "2":
        uploaded = files.upload()
        img_path = list(uploaded.keys())[0]
    else:
        print("‚ùå Invalid choice")
        return

    display(Image.open(img_path))
    predict_image(img_path)   # or predict_image(img_path)

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

prob = torch.softmax(veg_out, dim=1)
print(prob)

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

df["freshness_label"].value_counts(normalize=True)

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()

run_demo()